{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing as skp\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = dataset.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = keras.utils.normalize(X_train,axis=1)\n",
    "X_test = keras.utils.normalize(X_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.flatten().reshape(60000,784)\n",
    "X_test = X_test.flatten().reshape(10000,784)\n",
    "Y_train = Y_train.reshape(60000,1).astype('float32')\n",
    "Y_test = Y_test.reshape(10000,1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Enc = OneHotEncoder(sparse = False, categories = 'auto')\n",
    "Y_train = Enc.fit_transform(Y_train)\n",
    "Y_test = Enc.fit_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Net:\n",
    "    def __init__(self, ip_nodes, hdn_nodes, op_nodes):\n",
    "        self.W_01 = np.random.normal(0,1,(hdn_nodes, ip_nodes))\n",
    "        self.B_01 = np.random.normal(0,1,(hdn_nodes,1))\n",
    "        self.W_12 = np.random.normal(0,1,(op_nodes, hdn_nodes))\n",
    "        self.B_12 = np.random.normal(0,1,(op_nodes, 1))\n",
    "    \n",
    "    def Sigmoid(self, Z):\n",
    "        return (1/(1+(np.exp(-Z))))\n",
    "    \n",
    "    def Softmax(self, Z):\n",
    "        return ((np.exp(Z))/(np.exp(Z).sum()))\n",
    "    \n",
    "    def Predict(self, X):\n",
    "        self.Z1 = (self.W_01 @ X.T) + self.B_01\n",
    "        self.A1 = self.Sigmoid(self.Z1)\n",
    "        self.Z2 = (self.W_12 @ self.A1) + self.B_12\n",
    "        self.A2 = self.Softmax(self.Z2)\n",
    "        return self.A2.T\n",
    "    \n",
    "    def Train(self, X_train, Y_train, Epochs, Batch_size, Alpha):\n",
    "        e = Epochs\n",
    "        while e>0:\n",
    "            itr = (X_train.shape[0]) // Batch_size\n",
    "            for i in range(itr):\n",
    "                # Forward Propogation\n",
    "                X = X_train[(Batch_size*i):(Batch_size*(i+1))]\n",
    "                Y = Y_train[(Batch_size*i):(Batch_size*(i+1))].T\n",
    "                self.Z1 =  (self.W_01 @ (X.T)) + self.B_01\n",
    "                self.A1 = self.Sigmoid(self.Z1)\n",
    "                self.Z2 = (self.W_12 @ self.A1) + self.B_12\n",
    "                self.A2 = self.Softmax(self.Z2)\n",
    "                \n",
    "                self.A1_t = self.A1.T\n",
    "                self.A2_t = self.A2.T\n",
    "                \n",
    "                if i == 0:\n",
    "                    Predictions = np.array(self.A2_t)\n",
    "                else:\n",
    "                    Predictions = np.vstack((Predictions,self.A2_t))\n",
    "                \n",
    "                # Loss Calculation\n",
    "                L = (Y.T * np.log(self.A2_t)).sum()\n",
    "                Loss = -(1/Batch_size) * L\n",
    "                    \n",
    "                # Calculate Gradients\n",
    "                dloss_B_12 = -(Y * (1 - self.A2))\n",
    "                dloss_W_12 = dloss_B_12 @ self.A1.T\n",
    "                dloss_B_01 = ((dloss_B_12.T @ self.W_12) * self.A1_t * (1 - self.A1_t)).T\n",
    "                dloss_W_01 = dloss_B_01 @ X\n",
    "                    \n",
    "                # Backpropogation\n",
    "                self.W_01 = self.W_01 - Alpha * dloss_W_01\n",
    "                self.B_01 = self.B_01 - Alpha * dloss_B_01\n",
    "                self.W_12 = self.W_12 - Alpha * dloss_W_12\n",
    "                self.B_12 = self.B_12 - Alpha * dloss_B_12\n",
    "                            \n",
    "            # Calculate Overall Loss\n",
    "            L_train = (Y_train * np.log(Predictions)).sum()\n",
    "            Train_loss = -(1/Y_train.shape[0]) * L_train\n",
    "            \n",
    "            Y_train_Orig = np.argmax(Y_train, axis=1)\n",
    "            Y_train_Predict = np.argmax(Predictions, axis=1)\n",
    "            \n",
    "            print(\"Epoch\",Epochs-e+1,\"    loss:\",Loss,\"    accuracy:\",accuracy_score(Y_train_Orig,Y_train_Predict), \"\\n\")\n",
    "            e = e - 1\n",
    "    \n",
    "    def Test(self, X_test, Y_test, Batch_size):\n",
    "        itr = (X_test.shape[0]) // Batch_size\n",
    "        for i in range(itr):\n",
    "            X = X_test[(Batch_size*i):(Batch_size*(i+1))]\n",
    "            Y_pred = self.Predict(X)\n",
    "            \n",
    "            if i == 0:\n",
    "                Y_predicted = np.array(Y_pred)\n",
    "            else:\n",
    "                Y_predicted = np.vstack((Y_predicted,Y_pred))\n",
    "        \n",
    "        L_test = (Y_test * np.log(Y_predicted)).sum()\n",
    "        Test_loss = -(1/Y_test.shape[0]) * L_test\n",
    "        \n",
    "        Y_test_Orig = np.argmax(Y_test, axis=1)\n",
    "        Y_test_Predict = np.argmax(Y_predicted, axis=1)\n",
    "        \n",
    "        print(classification_report(Y_test_Orig,Y_test_Predict))\n",
    "        print(confusion_matrix(Y_test_Orig,Y_test_Predict))\n",
    "        print(\"loss:\",Test_loss, \"accuracy:\",accuracy_score(Y_test_Orig,Y_test_Predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of nodes in input layer: 784\n",
      "Enter the number of nodes in 1st hidden layer: 256\n",
      "Enter the number of nodes in output layer: 10\n",
      "Enter the number of epochs: 5\n",
      "Enter the batch size: 1\n",
      "Enter the learning rate: 0.0001\n"
     ]
    }
   ],
   "source": [
    "ip = int(input(\"Enter the number of nodes in input layer: \"))\n",
    "hdn = int(input(\"Enter the number of nodes in 1st hidden layer: \"))\n",
    "op = int(input(\"Enter the number of nodes in output layer: \"))\n",
    "e = int(input(\"Enter the number of epochs: \"))\n",
    "batch = int(input(\"Enter the batch size: \"))\n",
    "lr = float(input(\"Enter the learning rate: \"))\n",
    "NN = Neural_Net(ip, hdn, op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1     loss: 7.660795216156919     accuracy: 0.18545 \n",
      "\n",
      "Epoch 2     loss: 4.099623898279769     accuracy: 0.3624 \n",
      "\n",
      "Epoch 3     loss: 2.748261894439406     accuracy: 0.46576666666666666 \n",
      "\n",
      "Epoch 4     loss: 2.6964890489739455     accuracy: 0.5219666666666667 \n",
      "\n",
      "Epoch 5     loss: 2.2548829189067274     accuracy: 0.55435 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "NN.Train(X_train, Y_train, e, batch, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.59      0.72       980\n",
      "           1       0.95      0.55      0.69      1135\n",
      "           2       0.70      0.54      0.61      1032\n",
      "           3       0.50      0.63      0.55      1010\n",
      "           4       0.67      0.55      0.60       982\n",
      "           5       0.42      0.49      0.45       892\n",
      "           6       0.82      0.53      0.64       958\n",
      "           7       0.84      0.56      0.67      1028\n",
      "           8       0.32      0.56      0.41       974\n",
      "           9       0.34      0.59      0.43      1009\n",
      "\n",
      "   micro avg       0.56      0.56      0.56     10000\n",
      "   macro avg       0.65      0.56      0.58     10000\n",
      "weighted avg       0.65      0.56      0.58     10000\n",
      "\n",
      "[[583   0   4  46   6 112  16   2  70 141]\n",
      " [  0 620   2 192   0   7  14   0 179 121]\n",
      " [ 10  11 556  35  15  24  31   5 204 141]\n",
      " [  7   5  11 632   3 186   5   4  89  68]\n",
      " [  0   0  41  16 537  24  13  19 172 160]\n",
      " [ 15   2   6 143  38 441   4  11 156  76]\n",
      " [ 25   9 129  10  40   8 505   3 112 117]\n",
      " [  4   2  22  54  41  34   6 575  59 231]\n",
      " [  3   4  15  98  18 161   4   7 547 117]\n",
      " [  1   0   8  49 106  56  15  60 120 594]]\n",
      "loss: 2.0008292277654123 accuracy: 0.559\n"
     ]
    }
   ],
   "source": [
    "NN.Test(X_test, Y_test, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
